// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Magic Modules and manual
//     changes will be clobbered when the file is regenerated.
//
//     Please read more about how to change this file in
//     .github/CONTRIBUTING.md.
//
// ----------------------------------------------------------------------------

package bigquery

import (
	"fmt"
	"regexp"

	"github.com/GoogleCloudPlatform/terraform-google-conversion/v2/cai2hcl/common"
	"github.com/GoogleCloudPlatform/terraform-google-conversion/v2/caiasset"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-provider-google-beta/google-beta/tpgresource"
	transport_tpg "github.com/hashicorp/terraform-provider-google-beta/google-beta/transport"
	"google.golang.org/api/googleapi"
)

var (
	bigqueryDatasetRegexp = regexp.MustCompile("projects/(.+)/datasets/(.+)")
	bigqueryTableRegexp   = regexp.MustCompile("projects/(.+)/datasets/(.+)/tables/(.+)")
)

const BigQueryJobAssetType string = "bigquery.googleapis.com/Job"

const BigQueryJobAssetNameRegex string = "projects/(?P<project>[^/]+)/jobs"

type BigQueryJobConverter struct {
	name   string
	schema map[string]*schema.Schema
}

func NewBigQueryJobConverter(name string, schema map[string]*schema.Schema) common.Converter {
	return &BigQueryJobConverter{
		name:   name,
		schema: schema,
	}
}

func (c *BigQueryJobConverter) Convert(assets []*caiasset.Asset) ([]*common.HCLResourceBlock, error) {
	var blocks []*common.HCLResourceBlock
	config := common.NewConfig()

	for _, asset := range assets {
		if asset == nil {
			continue
		}
		if asset.Resource != nil && asset.Resource.Data != nil {
			block, err := c.convertResourceData(asset, config)
			if err != nil {
				return nil, err
			}
			blocks = append(blocks, block)
		}
	}
	return blocks, nil
}

func (c *BigQueryJobConverter) convertResourceData(asset *caiasset.Asset, config *transport_tpg.Config) (*common.HCLResourceBlock, error) {
	if asset == nil || asset.Resource == nil || asset.Resource.Data == nil {
		return nil, fmt.Errorf("asset resource data is nil")
	}

	assetResourceData := asset.Resource.Data

	hcl, _ := resourceBigQueryJobRead(assetResourceData, config)

	ctyVal, err := common.MapToCtyValWithSchema(hcl, c.schema)
	if err != nil {
		return nil, err
	}

	resourceName := assetResourceData["name"].(string)

	return &common.HCLResourceBlock{
		Labels: []string{c.name, resourceName},
		Value:  ctyVal,
	}, nil
}

func resourceBigQueryJobRead(resource map[string]interface{}, config *transport_tpg.Config) (map[string]interface{}, error) {
	result := make(map[string]interface{})
	var resource_data *schema.ResourceData = nil

	result["user_email"] = flattenBigQueryJobUserEmail(resource["user_email"], resource_data, config)
	if flattenedProp := flattenBigQueryJobConfiguration(resource["configuration"], resource_data, config); flattenedProp != nil {
		if gerr, ok := flattenedProp.(*googleapi.Error); ok {
			return nil, fmt.Errorf("Error reading Job: %s", gerr)
		}
		casted := flattenedProp.([]interface{})[0]
		if casted != nil {
			for k, v := range casted.(map[string]interface{}) {
				result[k] = v
			}
		}
	}
	if flattenedProp := flattenBigQueryJobJobReference(resource["jobReference"], resource_data, config); flattenedProp != nil {
		if gerr, ok := flattenedProp.(*googleapi.Error); ok {
			return nil, fmt.Errorf("Error reading Job: %s", gerr)
		}
		casted := flattenedProp.([]interface{})[0]
		if casted != nil {
			for k, v := range casted.(map[string]interface{}) {
				result[k] = v
			}
		}
	}
	result["status"] = flattenBigQueryJobStatus(resource["status"], resource_data, config)

	return result, nil
}

func flattenBigQueryJobUserEmail(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfiguration(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["job_type"] =
		flattenBigQueryJobConfigurationJobType(original["jobType"], d, config)
	transformed["job_timeout_ms"] =
		flattenBigQueryJobConfigurationJobTimeoutMs(original["jobTimeoutMs"], d, config)
	transformed["labels"] =
		flattenBigQueryJobConfigurationLabels(original["labels"], d, config)
	transformed["query"] =
		flattenBigQueryJobConfigurationQuery(original["query"], d, config)
	transformed["load"] =
		flattenBigQueryJobConfigurationLoad(original["load"], d, config)
	transformed["copy"] =
		flattenBigQueryJobConfigurationCopy(original["copy"], d, config)
	transformed["extract"] =
		flattenBigQueryJobConfigurationExtract(original["extract"], d, config)
	transformed["terraform_labels"] =
		flattenBigQueryJobConfigurationTerraformLabels(original["labels"], d, config)
	transformed["effective_labels"] =
		flattenBigQueryJobConfigurationEffectiveLabels(original["labels"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobConfigurationJobType(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationJobTimeoutMs(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLabels(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}

	transformed := make(map[string]interface{})
	if l, ok := d.GetOkExists("labels"); ok {
		for k := range l.(map[string]interface{}) {
			transformed[k] = v.(map[string]interface{})[k]
		}
	}

	return transformed
}

func flattenBigQueryJobConfigurationQuery(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["query"] =
		flattenBigQueryJobConfigurationQueryQuery(original["query"], d, config)
	transformed["destination_table"] =
		flattenBigQueryJobConfigurationQueryDestinationTable(original["destinationTable"], d, config)
	transformed["user_defined_function_resources"] =
		flattenBigQueryJobConfigurationQueryUserDefinedFunctionResources(original["userDefinedFunctionResources"], d, config)
	transformed["create_disposition"] =
		flattenBigQueryJobConfigurationQueryCreateDisposition(original["createDisposition"], d, config)
	transformed["write_disposition"] =
		flattenBigQueryJobConfigurationQueryWriteDisposition(original["writeDisposition"], d, config)
	transformed["default_dataset"] =
		flattenBigQueryJobConfigurationQueryDefaultDataset(original["defaultDataset"], d, config)
	transformed["priority"] =
		flattenBigQueryJobConfigurationQueryPriority(original["priority"], d, config)
	transformed["allow_large_results"] =
		flattenBigQueryJobConfigurationQueryAllowLargeResults(original["allowLargeResults"], d, config)
	transformed["use_query_cache"] =
		flattenBigQueryJobConfigurationQueryUseQueryCache(original["useQueryCache"], d, config)
	transformed["flatten_results"] =
		flattenBigQueryJobConfigurationQueryFlattenResults(original["flattenResults"], d, config)
	transformed["maximum_billing_tier"] =
		flattenBigQueryJobConfigurationQueryMaximumBillingTier(original["maximumBillingTier"], d, config)
	transformed["maximum_bytes_billed"] =
		flattenBigQueryJobConfigurationQueryMaximumBytesBilled(original["maximumBytesBilled"], d, config)
	transformed["use_legacy_sql"] =
		flattenBigQueryJobConfigurationQueryUseLegacySql(original["useLegacySql"], d, config)
	transformed["parameter_mode"] =
		flattenBigQueryJobConfigurationQueryParameterMode(original["parameterMode"], d, config)
	transformed["schema_update_options"] =
		flattenBigQueryJobConfigurationQuerySchemaUpdateOptions(original["schemaUpdateOptions"], d, config)
	transformed["destination_encryption_configuration"] =
		flattenBigQueryJobConfigurationQueryDestinationEncryptionConfiguration(original["destinationEncryptionConfiguration"], d, config)
	transformed["script_options"] =
		flattenBigQueryJobConfigurationQueryScriptOptions(original["scriptOptions"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobConfigurationQueryQuery(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryDestinationTable(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["project_id"] = original["projectId"]
	transformed["dataset_id"] = original["datasetId"]
	transformed["table_id"] = original["tableId"]

	if bigqueryTableRegexp.MatchString(d.Get("query.0.destination_table.0.table_id").(string)) {
		// The user specified the table_id as a URL, so store it in state that way
		transformed["table_id"] = fmt.Sprintf("projects/%s/datasets/%s/tables/%s", transformed["project_id"], transformed["dataset_id"], transformed["table_id"])
	}
	return []interface{}{transformed}
}

func flattenBigQueryJobConfigurationQueryUserDefinedFunctionResources(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}
	l := v.([]interface{})
	transformed := make([]interface{}, 0, len(l))
	for _, raw := range l {
		original := raw.(map[string]interface{})
		if len(original) < 1 {
			// Do not include empty json objects coming back from the api
			continue
		}
		transformed = append(transformed, map[string]interface{}{
			"resource_uri": flattenBigQueryJobConfigurationQueryUserDefinedFunctionResourcesResourceUri(original["resourceUri"], d, config),
			"inline_code":  flattenBigQueryJobConfigurationQueryUserDefinedFunctionResourcesInlineCode(original["inlineCode"], d, config),
		})
	}
	return transformed
}
func flattenBigQueryJobConfigurationQueryUserDefinedFunctionResourcesResourceUri(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryUserDefinedFunctionResourcesInlineCode(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryCreateDisposition(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryWriteDisposition(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryDefaultDataset(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["project_id"] = original["projectId"]
	transformed["dataset_id"] = original["datasetId"]

	if bigqueryDatasetRegexp.MatchString(d.Get("query.0.default_dataset.0.dataset_id").(string)) {
		// The user specified the dataset_id as a URL, so store it in state that way
		transformed["dataset_id"] = fmt.Sprintf("projects/%s/datasets/%s", transformed["project_id"], transformed["dataset_id"])
	}
	return []interface{}{transformed}
}

func flattenBigQueryJobConfigurationQueryPriority(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryAllowLargeResults(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryUseQueryCache(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryFlattenResults(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryMaximumBillingTier(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := tpgresource.StringToFixed64(strVal); err == nil {
			return intVal
		}
	}

	// number values are represented as float64
	if floatVal, ok := v.(float64); ok {
		intVal := int(floatVal)
		return intVal
	}

	return v // let terraform core handle it otherwise
}

func flattenBigQueryJobConfigurationQueryMaximumBytesBilled(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryUseLegacySql(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryParameterMode(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQuerySchemaUpdateOptions(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

// KmsKeyName switched from using a key name to a key version, this will separate the key name from the key version and save them
// separately in state.  https://github.com/hashicorp/terraform-provider-google/issues/9208
func flattenBigQueryJobConfigurationQueryDestinationEncryptionConfiguration(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return []map[string]interface{}{}
	}

	kmsKeyName := v.(map[string]interface{})["kmsKeyName"].(string)
	re := regexp.MustCompile(`(projects/.*/locations/.*/keyRings/.*/cryptoKeys/.*)/cryptoKeyVersions/.*`)
	paths := re.FindStringSubmatch(kmsKeyName)

	if len(paths) > 0 {
		return []map[string]interface{}{
			{
				"kms_key_name":    paths[1],
				"kms_key_version": kmsKeyName,
			},
		}
	}

	//	The key name was returned, no need to set the version
	return []map[string]interface{}{{"kms_key_name": kmsKeyName, "kms_key_version": ""}}

}

func flattenBigQueryJobConfigurationQueryScriptOptions(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["statement_timeout_ms"] =
		flattenBigQueryJobConfigurationQueryScriptOptionsStatementTimeoutMs(original["statementTimeoutMs"], d, config)
	transformed["statement_byte_budget"] =
		flattenBigQueryJobConfigurationQueryScriptOptionsStatementByteBudget(original["statementByteBudget"], d, config)
	transformed["key_result_statement"] =
		flattenBigQueryJobConfigurationQueryScriptOptionsKeyResultStatement(original["keyResultStatement"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobConfigurationQueryScriptOptionsStatementTimeoutMs(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryScriptOptionsStatementByteBudget(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationQueryScriptOptionsKeyResultStatement(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoad(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["source_uris"] =
		flattenBigQueryJobConfigurationLoadSourceUris(original["sourceUris"], d, config)
	transformed["destination_table"] =
		flattenBigQueryJobConfigurationLoadDestinationTable(original["destinationTable"], d, config)
	transformed["create_disposition"] =
		flattenBigQueryJobConfigurationLoadCreateDisposition(original["createDisposition"], d, config)
	transformed["write_disposition"] =
		flattenBigQueryJobConfigurationLoadWriteDisposition(original["writeDisposition"], d, config)
	transformed["null_marker"] =
		flattenBigQueryJobConfigurationLoadNullMarker(original["nullMarker"], d, config)
	transformed["field_delimiter"] =
		flattenBigQueryJobConfigurationLoadFieldDelimiter(original["fieldDelimiter"], d, config)
	transformed["skip_leading_rows"] =
		flattenBigQueryJobConfigurationLoadSkipLeadingRows(original["skipLeadingRows"], d, config)
	transformed["encoding"] =
		flattenBigQueryJobConfigurationLoadEncoding(original["encoding"], d, config)
	transformed["quote"] =
		flattenBigQueryJobConfigurationLoadQuote(original["quote"], d, config)
	transformed["max_bad_records"] =
		flattenBigQueryJobConfigurationLoadMaxBadRecords(original["maxBadRecords"], d, config)
	transformed["allow_quoted_newlines"] =
		flattenBigQueryJobConfigurationLoadAllowQuotedNewlines(original["allowQuotedNewlines"], d, config)
	transformed["source_format"] =
		flattenBigQueryJobConfigurationLoadSourceFormat(original["sourceFormat"], d, config)
	transformed["json_extension"] =
		flattenBigQueryJobConfigurationLoadJsonExtension(original["jsonExtension"], d, config)
	transformed["allow_jagged_rows"] =
		flattenBigQueryJobConfigurationLoadAllowJaggedRows(original["allowJaggedRows"], d, config)
	transformed["ignore_unknown_values"] =
		flattenBigQueryJobConfigurationLoadIgnoreUnknownValues(original["ignoreUnknownValues"], d, config)
	transformed["projection_fields"] =
		flattenBigQueryJobConfigurationLoadProjectionFields(original["projectionFields"], d, config)
	transformed["autodetect"] =
		flattenBigQueryJobConfigurationLoadAutodetect(original["autodetect"], d, config)
	transformed["schema_update_options"] =
		flattenBigQueryJobConfigurationLoadSchemaUpdateOptions(original["schemaUpdateOptions"], d, config)
	transformed["time_partitioning"] =
		flattenBigQueryJobConfigurationLoadTimePartitioning(original["timePartitioning"], d, config)
	transformed["destination_encryption_configuration"] =
		flattenBigQueryJobConfigurationLoadDestinationEncryptionConfiguration(original["destinationEncryptionConfiguration"], d, config)
	transformed["parquet_options"] =
		flattenBigQueryJobConfigurationLoadParquetOptions(original["parquetOptions"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobConfigurationLoadSourceUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadDestinationTable(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["project_id"] = original["projectId"]
	transformed["dataset_id"] = original["datasetId"]
	transformed["table_id"] = original["tableId"]

	if bigqueryTableRegexp.MatchString(d.Get("load.0.destination_table.0.table_id").(string)) {
		// The user specified the table_id as a URL, so store it in state that way
		transformed["table_id"] = fmt.Sprintf("projects/%s/datasets/%s/tables/%s", transformed["project_id"], transformed["dataset_id"], transformed["table_id"])
	}
	return []interface{}{transformed}
}

func flattenBigQueryJobConfigurationLoadCreateDisposition(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadWriteDisposition(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadNullMarker(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadFieldDelimiter(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadSkipLeadingRows(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := tpgresource.StringToFixed64(strVal); err == nil {
			return intVal
		}
	}

	// number values are represented as float64
	if floatVal, ok := v.(float64); ok {
		intVal := int(floatVal)
		return intVal
	}

	return v // let terraform core handle it otherwise
}

func flattenBigQueryJobConfigurationLoadEncoding(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadQuote(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadMaxBadRecords(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := tpgresource.StringToFixed64(strVal); err == nil {
			return intVal
		}
	}

	// number values are represented as float64
	if floatVal, ok := v.(float64); ok {
		intVal := int(floatVal)
		return intVal
	}

	return v // let terraform core handle it otherwise
}

func flattenBigQueryJobConfigurationLoadAllowQuotedNewlines(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadSourceFormat(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadJsonExtension(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadAllowJaggedRows(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadIgnoreUnknownValues(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadProjectionFields(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadAutodetect(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadSchemaUpdateOptions(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadTimePartitioning(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["type"] =
		flattenBigQueryJobConfigurationLoadTimePartitioningType(original["type"], d, config)
	transformed["expiration_ms"] =
		flattenBigQueryJobConfigurationLoadTimePartitioningExpirationMs(original["expirationMs"], d, config)
	transformed["field"] =
		flattenBigQueryJobConfigurationLoadTimePartitioningField(original["field"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobConfigurationLoadTimePartitioningType(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadTimePartitioningExpirationMs(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadTimePartitioningField(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

// KmsKeyName switched from using a key name to a key version, this will separate the key name from the key version and save them
// separately in state.  https://github.com/hashicorp/terraform-provider-google/issues/9208
func flattenBigQueryJobConfigurationLoadDestinationEncryptionConfiguration(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return []map[string]interface{}{}
	}

	kmsKeyName := v.(map[string]interface{})["kmsKeyName"].(string)
	re := regexp.MustCompile(`(projects/.*/locations/.*/keyRings/.*/cryptoKeys/.*)/cryptoKeyVersions/.*`)
	paths := re.FindStringSubmatch(kmsKeyName)

	if len(paths) > 0 {
		return []map[string]interface{}{
			{
				"kms_key_name":    paths[1],
				"kms_key_version": kmsKeyName,
			},
		}
	}

	//	The key name was returned, no need to set the version
	return []map[string]interface{}{{"kms_key_name": kmsKeyName, "kms_key_version": ""}}

}

func flattenBigQueryJobConfigurationLoadParquetOptions(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["enum_as_string"] =
		flattenBigQueryJobConfigurationLoadParquetOptionsEnumAsString(original["enumAsString"], d, config)
	transformed["enable_list_inference"] =
		flattenBigQueryJobConfigurationLoadParquetOptionsEnableListInference(original["enableListInference"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobConfigurationLoadParquetOptionsEnumAsString(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationLoadParquetOptionsEnableListInference(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationCopy(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["source_tables"] =
		flattenBigQueryJobConfigurationCopySourceTables(original["sourceTables"], d, config)
	transformed["destination_table"] =
		flattenBigQueryJobConfigurationCopyDestinationTable(original["destinationTable"], d, config)
	transformed["create_disposition"] =
		flattenBigQueryJobConfigurationCopyCreateDisposition(original["createDisposition"], d, config)
	transformed["write_disposition"] =
		flattenBigQueryJobConfigurationCopyWriteDisposition(original["writeDisposition"], d, config)
	transformed["destination_encryption_configuration"] =
		flattenBigQueryJobConfigurationCopyDestinationEncryptionConfiguration(original["destinationEncryptionConfiguration"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobConfigurationCopySourceTables(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}
	l := v.([]interface{})
	transformed := make([]interface{}, 0, len(l))
	for i, raw := range l {
		original := raw.(map[string]interface{})
		if len(original) < 1 {
			// Do not include empty json objects coming back from the api
			continue
		}
		t := map[string]interface{}{
			"project_id": original["projectId"],
			"dataset_id": original["datasetId"],
			"table_id":   original["tableId"],
		}

		if bigqueryTableRegexp.MatchString(d.Get(fmt.Sprintf("copy.0.source_tables.%d.table_id", i)).(string)) {
			// The user specified the table_id as a URL, so store it in state that way
			t["table_id"] = fmt.Sprintf("projects/%s/datasets/%s/tables/%s", t["project_id"], t["dataset_id"], t["table_id"])
		}
		transformed = append(transformed, t)
	}

	return transformed
}

func flattenBigQueryJobConfigurationCopyDestinationTable(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["project_id"] = original["projectId"]
	transformed["dataset_id"] = original["datasetId"]
	transformed["table_id"] = original["tableId"]

	if bigqueryTableRegexp.MatchString(d.Get("copy.0.destination_table.0.table_id").(string)) {
		// The user specified the table_id as a URL, so store it in state that way
		transformed["table_id"] = fmt.Sprintf("projects/%s/datasets/%s/tables/%s", transformed["project_id"], transformed["dataset_id"], transformed["table_id"])
	}
	return []interface{}{transformed}
}

func flattenBigQueryJobConfigurationCopyCreateDisposition(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationCopyWriteDisposition(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

// KmsKeyName switched from using a key name to a key version, this will separate the key name from the key version and save them
// separately in state.  https://github.com/hashicorp/terraform-provider-google/issues/9208
func flattenBigQueryJobConfigurationCopyDestinationEncryptionConfiguration(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return []map[string]interface{}{}
	}

	kmsKeyName := v.(map[string]interface{})["kmsKeyName"].(string)
	re := regexp.MustCompile(`(projects/.*/locations/.*/keyRings/.*/cryptoKeys/.*)/cryptoKeyVersions/.*`)
	paths := re.FindStringSubmatch(kmsKeyName)

	if len(paths) > 0 {
		return []map[string]interface{}{
			{
				"kms_key_name":    paths[1],
				"kms_key_version": kmsKeyName,
			},
		}
	}

	//	The key name was returned, no need to set the version
	return []map[string]interface{}{{"kms_key_name": kmsKeyName, "kms_key_version": ""}}

}

func flattenBigQueryJobConfigurationExtract(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["destination_uris"] =
		flattenBigQueryJobConfigurationExtractDestinationUris(original["destinationUris"], d, config)
	transformed["print_header"] =
		flattenBigQueryJobConfigurationExtractPrintHeader(original["printHeader"], d, config)
	transformed["field_delimiter"] =
		flattenBigQueryJobConfigurationExtractFieldDelimiter(original["fieldDelimiter"], d, config)
	transformed["destination_format"] =
		flattenBigQueryJobConfigurationExtractDestinationFormat(original["destinationFormat"], d, config)
	transformed["compression"] =
		flattenBigQueryJobConfigurationExtractCompression(original["compression"], d, config)
	transformed["use_avro_logical_types"] =
		flattenBigQueryJobConfigurationExtractUseAvroLogicalTypes(original["useAvroLogicalTypes"], d, config)
	transformed["source_table"] =
		flattenBigQueryJobConfigurationExtractSourceTable(original["sourceTable"], d, config)
	transformed["source_model"] =
		flattenBigQueryJobConfigurationExtractSourceModel(original["sourceModel"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobConfigurationExtractDestinationUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationExtractPrintHeader(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationExtractFieldDelimiter(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationExtractDestinationFormat(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationExtractCompression(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationExtractUseAvroLogicalTypes(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationExtractSourceTable(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["project_id"] = original["projectId"]
	transformed["dataset_id"] = original["datasetId"]
	transformed["table_id"] = original["tableId"]

	if bigqueryTableRegexp.MatchString(d.Get("extract.0.source_table.0.table_id").(string)) {
		// The user specified the table_id as a URL, so store it in state that way
		transformed["table_id"] = fmt.Sprintf("projects/%s/datasets/%s/tables/%s", transformed["project_id"], transformed["dataset_id"], transformed["table_id"])
	}
	return []interface{}{transformed}
}

func flattenBigQueryJobConfigurationExtractSourceModel(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["project_id"] =
		flattenBigQueryJobConfigurationExtractSourceModelProjectId(original["projectId"], d, config)
	transformed["dataset_id"] =
		flattenBigQueryJobConfigurationExtractSourceModelDatasetId(original["datasetId"], d, config)
	transformed["model_id"] =
		flattenBigQueryJobConfigurationExtractSourceModelModelId(original["modelId"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobConfigurationExtractSourceModelProjectId(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationExtractSourceModelDatasetId(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationExtractSourceModelModelId(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobConfigurationTerraformLabels(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}

	transformed := make(map[string]interface{})
	if l, ok := d.GetOkExists("terraform_labels"); ok {
		for k := range l.(map[string]interface{}) {
			transformed[k] = v.(map[string]interface{})[k]
		}
	}

	return transformed
}

func flattenBigQueryJobConfigurationEffectiveLabels(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobJobReference(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["job_id"] =
		flattenBigQueryJobJobReferenceJobId(original["jobId"], d, config)
	transformed["location"] =
		flattenBigQueryJobJobReferenceLocation(original["location"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobJobReferenceJobId(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobJobReferenceLocation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobStatus(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["error_result"] =
		flattenBigQueryJobStatusErrorResult(original["errorResult"], d, config)
	transformed["errors"] =
		flattenBigQueryJobStatusErrors(original["errors"], d, config)
	transformed["state"] =
		flattenBigQueryJobStatusState(original["state"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobStatusErrorResult(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["reason"] =
		flattenBigQueryJobStatusErrorResultReason(original["reason"], d, config)
	transformed["location"] =
		flattenBigQueryJobStatusErrorResultLocation(original["location"], d, config)
	transformed["message"] =
		flattenBigQueryJobStatusErrorResultMessage(original["message"], d, config)
	return []interface{}{transformed}
}
func flattenBigQueryJobStatusErrorResultReason(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobStatusErrorResultLocation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobStatusErrorResultMessage(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobStatusErrors(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}
	l := v.([]interface{})
	transformed := make([]interface{}, 0, len(l))
	for _, raw := range l {
		original := raw.(map[string]interface{})
		if len(original) < 1 {
			// Do not include empty json objects coming back from the api
			continue
		}
		transformed = append(transformed, map[string]interface{}{
			"reason":   flattenBigQueryJobStatusErrorsReason(original["reason"], d, config),
			"location": flattenBigQueryJobStatusErrorsLocation(original["location"], d, config),
			"message":  flattenBigQueryJobStatusErrorsMessage(original["message"], d, config),
		})
	}
	return transformed
}
func flattenBigQueryJobStatusErrorsReason(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobStatusErrorsLocation(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobStatusErrorsMessage(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigQueryJobStatusState(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}
