// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Magic Modules and manual
//     changes will be clobbered when the file is regenerated.
//
//     Please read more about how to change this file in
//     .github/CONTRIBUTING.md.
//
// ----------------------------------------------------------------------------

package bigquerydatatransfer

import (
	"context"
	"fmt"

	"github.com/GoogleCloudPlatform/terraform-google-conversion/v2/cai2hcl/common"
	"github.com/GoogleCloudPlatform/terraform-google-conversion/v2/caiasset"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-provider-google-beta/google-beta/tpgresource"
	transport_tpg "github.com/hashicorp/terraform-provider-google-beta/google-beta/transport"
)

var sensitiveParams = []string{"secret_access_key"}

func sensitiveParamCustomizeDiff(_ context.Context, diff *schema.ResourceDiff, v interface{}) error {
	for _, sp := range sensitiveParams {
		mapLabel := diff.Get("params." + sp).(string)
		authLabel := diff.Get("sensitive_params.0." + sp).(string)
		if mapLabel != "" && authLabel != "" {
			return fmt.Errorf("Sensitive param [%s] cannot be set in both `params` and the `sensitive_params` block.", sp)
		}
	}
	return nil
}

// This customizeDiff is to use ForceNew for params fields data_path_template or data_path and
// destination_table_name_template only if the value of "data_source_id" is "google_cloud_storage" or "amazon_s3".
func ParamsCustomizeDiffFunc(diff tpgresource.TerraformResourceDiff) error {
	old, new := diff.GetChange("params")
	dsId := diff.Get("data_source_id").(string)
	oldParams := old.(map[string]interface{})
	newParams := new.(map[string]interface{})
	var err error

	switch dsId {
	case "google_cloud_storage":
		if oldParams["data_path_template"] != nil && newParams["data_path_template"] != nil && oldParams["data_path_template"].(string) != newParams["data_path_template"].(string) {
			err = diff.ForceNew("params")
			if err != nil {
				return fmt.Errorf("ForceNew failed for params, old - %v and new - %v", oldParams, newParams)
			}
			return nil
		}

		if oldParams["destination_table_name_template"] != nil && newParams["destination_table_name_template"] != nil && oldParams["destination_table_name_template"].(string) != newParams["destination_table_name_template"].(string) {
			err = diff.ForceNew("params")
			if err != nil {
				return fmt.Errorf("ForceNew failed for params, old - %v and new - %v", oldParams, newParams)
			}
			return nil
		}
	case "amazon_s3":
		if oldParams["data_path"] != nil && newParams["data_path"] != nil && oldParams["data_path"].(string) != newParams["data_path"].(string) {
			err = diff.ForceNew("params")
			if err != nil {
				return fmt.Errorf("ForceNew failed for params, old - %v and new - %v", oldParams, newParams)
			}
			return nil
		}

		if oldParams["destination_table_name_template"] != nil && newParams["destination_table_name_template"] != nil && oldParams["destination_table_name_template"].(string) != newParams["destination_table_name_template"].(string) {
			err = diff.ForceNew("params")
			if err != nil {
				return fmt.Errorf("ForceNew failed for params, old - %v and new - %v", oldParams, newParams)
			}
			return nil
		}
	}
	return nil
}
func paramsCustomizeDiff(_ context.Context, diff *schema.ResourceDiff, v interface{}) error {
	return ParamsCustomizeDiffFunc(diff)
}

const BigqueryDataTransferConfigAssetType string = "bigquerydatatransfer.googleapis.com/Config"

const BigqueryDataTransferConfigAssetNameRegex string = "projects/(?P<project>[^/]+)/locations/(?P<location>[^/]+)/transferConfigs?serviceAccountName=(?P<service_account_name>[^/]+)"

type BigqueryDataTransferConfigConverter struct {
	name   string
	schema map[string]*schema.Schema
}

func NewBigqueryDataTransferConfigConverter(name string, schema map[string]*schema.Schema) common.Converter {
	return &BigqueryDataTransferConfigConverter{
		name:   name,
		schema: schema,
	}
}

func (c *BigqueryDataTransferConfigConverter) Convert(assets []*caiasset.Asset) ([]*common.HCLResourceBlock, error) {
	var blocks []*common.HCLResourceBlock
	config := common.NewConfig()

	for _, asset := range assets {
		if asset == nil {
			continue
		}
		if asset.Resource != nil && asset.Resource.Data != nil {
			block, err := c.convertResourceData(asset, config)
			if err != nil {
				return nil, err
			}
			blocks = append(blocks, block)
		}
	}
	return blocks, nil
}

func (c *BigqueryDataTransferConfigConverter) convertResourceData(asset *caiasset.Asset, config *transport_tpg.Config) (*common.HCLResourceBlock, error) {
	if asset == nil || asset.Resource == nil || asset.Resource.Data == nil {
		return nil, fmt.Errorf("asset resource data is nil")
	}

	assetResourceData := asset.Resource.Data

	hcl, _ := resourceBigqueryDataTransferConfigRead(assetResourceData, config)

	ctyVal, err := common.MapToCtyValWithSchema(hcl, c.schema)
	if err != nil {
		return nil, err
	}

	resourceName := assetResourceData["name"].(string)

	return &common.HCLResourceBlock{
		Labels: []string{c.name, resourceName},
		Value:  ctyVal,
	}, nil
}

func resourceBigqueryDataTransferConfigRead(resource map[string]interface{}, config *transport_tpg.Config) (map[string]interface{}, error) {
	result := make(map[string]interface{})
	var resource_data *schema.ResourceData = nil

	result["display_name"] = flattenBigqueryDataTransferConfigDisplayName(resource["displayName"], resource_data, config)
	result["name"] = flattenBigqueryDataTransferConfigName(resource["name"], resource_data, config)
	result["destination_dataset_id"] = flattenBigqueryDataTransferConfigDestinationDatasetId(resource["destinationDatasetId"], resource_data, config)
	result["data_source_id"] = flattenBigqueryDataTransferConfigDataSourceId(resource["dataSourceId"], resource_data, config)
	result["schedule"] = flattenBigqueryDataTransferConfigSchedule(resource["schedule"], resource_data, config)
	result["schedule_options"] = flattenBigqueryDataTransferConfigScheduleOptions(resource["scheduleOptions"], resource_data, config)
	result["email_preferences"] = flattenBigqueryDataTransferConfigEmailPreferences(resource["emailPreferences"], resource_data, config)
	result["notification_pubsub_topic"] = flattenBigqueryDataTransferConfigNotificationPubsubTopic(resource["notificationPubsubTopic"], resource_data, config)
	result["data_refresh_window_days"] = flattenBigqueryDataTransferConfigDataRefreshWindowDays(resource["dataRefreshWindowDays"], resource_data, config)
	result["disabled"] = flattenBigqueryDataTransferConfigDisabled(resource["disabled"], resource_data, config)
	result["params"] = flattenBigqueryDataTransferConfigParams(resource["params"], resource_data, config)

	return result, nil
}

func flattenBigqueryDataTransferConfigDisplayName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryDataTransferConfigName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryDataTransferConfigDestinationDatasetId(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryDataTransferConfigDataSourceId(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryDataTransferConfigSchedule(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryDataTransferConfigScheduleOptions(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["disable_auto_scheduling"] =
		flattenBigqueryDataTransferConfigScheduleOptionsDisableAutoScheduling(original["disableAutoScheduling"], d, config)
	transformed["start_time"] =
		flattenBigqueryDataTransferConfigScheduleOptionsStartTime(original["startTime"], d, config)
	transformed["end_time"] =
		flattenBigqueryDataTransferConfigScheduleOptionsEndTime(original["endTime"], d, config)
	return []interface{}{transformed}
}
func flattenBigqueryDataTransferConfigScheduleOptionsDisableAutoScheduling(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryDataTransferConfigScheduleOptionsStartTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryDataTransferConfigScheduleOptionsEndTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryDataTransferConfigEmailPreferences(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["enable_failure_email"] =
		flattenBigqueryDataTransferConfigEmailPreferencesEnableFailureEmail(original["enableFailureEmail"], d, config)
	return []interface{}{transformed}
}
func flattenBigqueryDataTransferConfigEmailPreferencesEnableFailureEmail(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryDataTransferConfigNotificationPubsubTopic(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryDataTransferConfigDataRefreshWindowDays(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	// Handles the string fixed64 format
	if strVal, ok := v.(string); ok {
		if intVal, err := tpgresource.StringToFixed64(strVal); err == nil {
			return intVal
		}
	}

	// number values are represented as float64
	if floatVal, ok := v.(float64); ok {
		intVal := int(floatVal)
		return intVal
	}

	return v // let terraform core handle it otherwise
}

func flattenBigqueryDataTransferConfigDisabled(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenBigqueryDataTransferConfigParams(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return v
	}

	kv := v.(map[string]interface{})

	res := make(map[string]string)
	for key, value := range kv {
		res[key] = fmt.Sprintf("%v", value)
	}
	return res
}
